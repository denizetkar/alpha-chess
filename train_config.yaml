# Default configuration for the training script

# Training parameters
training:
  num_iterations: 1 # Number of self-play iterations
  num_games_per_iteration: 1 # Number of self-play games per iteration
  num_epochs: 1 # Number of epochs for training the neural network
  batch_size: 1 # Batch size for neural network training
  num_training_steps: 1 # Number of training steps per iteration
  learning_rate: 0.001 # Initial learning rate
  l2_regularization: 0.0001 # L2 regularization strength
  momentum: 0.9 # Momentum for optimizer
  clip_norm: 10 # Gradient clipping norm
  value_loss_weight: 1.0 # Weight for value loss in total loss
  policy_loss_weight: 1.0 # Weight for policy loss in total loss
  temperature: 1.0 # Temperature for policy distribution during self-play
  cpu_threads: 1 # Number of CPU threads for data loading
  replay_buffer_capacity: 100 # Maximum number of experiences to store in the replay buffer
  use_mixed_precision: false # Enable or disable mixed precision training

  # Learning rate scheduler configuration
  lr_scheduler:
    use_scheduler: false # Set to true to enable a learning rate scheduler
    type: "cosine_annealing" # Type of scheduler: "cosine_annealing" or "exponential"
    t_max: 1 # For CosineAnnealingLR: Maximum number of iterations
    eta_min: 0.00001 # For CosineAnnealingLR: Minimum learning rate
    gamma: 0.9 # For ExponentialLR: Multiplicative factor of learning rate decay
  seed: null # Set a specific random seed for reproducibility

# MCTS parameters
mcts:
  num_simulations: 1 # Number of MCTS simulations per move
  c_puct: 1.0 # PUCT constant
  temp_threshold: 1 # Move number after which temperature is set to 0
  max_depth: 2 # Maximum search depth for MCTS
  simulations_per_move: 10 # Number of MCTS simulations per move
  dirichlet_alpha: 0.3 # Alpha for Dirichlet noise
  dirichlet_epsilon: 0.25 # Epsilon for Dirichlet noise

# Model parameters
model:
  num_residual_blocks: 1 # Number of residual blocks in the neural network
  num_filters: 8 # Number of filters in convolutional layers
  use_torch_compile: false # Whether to use torch.compile for model optimization

# Checkpointing and logging
checkpointing:
  checkpoint_dir: "checkpoints" # Directory to save model checkpoints
  save_interval: 1 # Save checkpoint every N iterations
  log_interval: 1 # Log training metrics every N epochs
  checkpoint_path: "checkpoints/model.pth" # Path to save/load model checkpoints
  load_checkpoint: false # Whether to load a checkpoint at the start of training
  load_checkpoint_path: null # Path to a checkpoint file to load

# Logging configuration
logging:
  tensorboard_log_dir: "runs" # Directory for TensorBoard logs

# Device configuration
device: "cpu" # Device to use for training (e.g., "cuda" or "cpu")
